import { Storage } from '@google-cloud/storage'
import { logger } from '@/lib/logger'
import { existsSync } from 'fs'
import { GeminiDirectService } from '@/lib/gemini-direct'
import { getVertexAIConfig } from '@/lib/config'
import { getAuthManager } from '@/lib/auth'

export interface VideoAnalysis {
  generatedTranscript: string
  sceneBreakdown: SceneDescription[]
  characters: CharacterDescription[]
  dialogues: DialogueSegment[]
  visualElements: VisualElement[]
  storyStructure: StoryStructure
  audioAnalysis: AudioAnalysis
  mood: string
  themes: string[]
  cameraWork: string
  keyMoments: KeyMoment[]
  contentSummary: string
  confidence: number
}

export interface SceneDescription {
  startTime: number
  endTime: number
  description: string
  setting: string
  actions: string[]
  visualDetails: string
}

export interface CharacterDescription {
  name: string
  description: string
  role: string
  appearances: TimeRange[]
  characteristics: string
}

export interface DialogueSegment {
  startTime: number
  endTime: number
  speaker: string
  text: string
  emotion: string
  language: string
}

export interface VisualElement {
  type: 'object' | 'text' | 'effect' | 'transition' | 'background'
  name: string
  description: string
  timeRanges: TimeRange[]
  importance: 'high' | 'medium' | 'low'
}

export interface TimeRange {
  startTime: number
  endTime: number
}

export interface StoryStructure {
  hook: string          // å‰ 3 ç§’é‰¤å­
  development: string   // ç™¼å±•éšæ®µ
  climax: string        // é«˜æ½®æ™‚åˆ»
  resolution: string    // çµå°¾è§£æ±º
}

export interface KeyMoment {
  timestamp: number
  description: string
  importance: 'high' | 'medium' | 'low'
  type: 'visual' | 'audio' | 'action' | 'dialogue'
  reason: string
}

export interface AudioAnalysis {
  hasDialogue: boolean
  backgroundMusic: string
  soundEffects: string[]
  voiceCharacteristics: string
}

export class GeminiVideoAnalyzer {
  private storage: Storage
  private geminiService: GeminiDirectService
  private projectId: string
  private location: string

  constructor() {
    this.projectId = process.env.GOOGLE_CLOUD_PROJECT_ID || 'fechen-aifactory'
    this.location = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1'
    
    // åˆå§‹åŒ– Gemini Direct Service
    this.geminiService = new GeminiDirectService()

    // åˆå§‹åŒ– Cloud Storage (ç”¨æ–¼è‡¨æ™‚ä¸Šå‚³)
    this.storage = new Storage({
      projectId: this.projectId
    })
  }

  async analyzeVideoFile(filePath: string, videoId: string): Promise<VideoAnalysis> {
    const startTime = Date.now()
    logger.info(`ğŸ¬ Starting video analysis for ${videoId}`)

    try {
      // 1. ä¸Šå‚³åˆ° GCS (è‡¨æ™‚)
      const gcsUri = await this.uploadToTempStorage(filePath, videoId)
      
      // 2. ä½¿ç”¨ Gemini åˆ†æè¦–é »
      const analysis = await this.performVideoAnalysis(gcsUri, videoId)
      
      // 3. æ¸…ç† GCS è‡¨æ™‚æª”æ¡ˆ
      await this.cleanupTempStorage(gcsUri)
      
      const elapsed = Date.now() - startTime
      logger.info(`âœ… Video analysis completed in ${elapsed}ms`, {
        videoId,
        confidence: analysis.confidence
      })

      return analysis

    } catch (error) {
      logger.error(`âŒ Video analysis failed for ${videoId}`, { error })
      throw new Error(`Video analysis failed: ${error}`)
    }
  }

  private async uploadToTempStorage(filePath: string, videoId: string): Promise<string> {
    if (!existsSync(filePath)) {
      throw new Error(`Video file not found: ${filePath}`)
    }

    const bucketName = 'storycraft-video-temp'
    const fileName = `shorts/${videoId}_${Date.now()}.mp4`
    
    try {
      // ç¢ºä¿ bucket å­˜åœ¨
      const bucket = this.storage.bucket(bucketName)
      const [exists] = await bucket.exists()
      
      if (!exists) {
        logger.info(`Creating temporary storage bucket: ${bucketName}`)
        await bucket.create({
          location: this.location,
          storageClass: 'STANDARD',
          lifecycle: {
            rule: [{
              action: { type: 'Delete' },
              condition: { age: 1 } // 1 å¤©å¾Œè‡ªå‹•åˆªé™¤
            }]
          }
        })
      }

      // ä¸Šå‚³æª”æ¡ˆ
      logger.info(`ğŸ“¤ Uploading to GCS: gs://${bucketName}/${fileName}`)
      await bucket.upload(filePath, {
        destination: fileName,
        metadata: {
          cacheControl: 'no-cache',
          metadata: {
            videoId,
            uploadTime: new Date().toISOString(),
            purpose: 'shorts-analysis'
          }
        }
      })

      return `gs://${bucketName}/${fileName}`

    } catch (error) {
      logger.error('Failed to upload to GCS', { filePath, error })
      throw new Error(`GCS upload failed: ${error}`)
    }
  }

  private async performVideoAnalysis(gcsUri: string, videoId: string): Promise<VideoAnalysis> {
    try {
      // åˆ†éšæ®µæç¤ºç­–ç•¥
      const prompts = [
        this.createAnalysisPrompt(),           // æ¥µç°¡ç‰ˆæœ¬
        this.createMinimalAnalysisPrompt()     // è¶…ç´šç²¾ç°¡ç‰ˆæœ¬ï¼ˆå‚™ç”¨ï¼‰
      ]
      
      logger.info(`ğŸ¬ Starting real Gemini 2.5 Flash video analysis for: ${videoId}`)
      logger.info(`ğŸ“¹ Video GCS URI: ${gcsUri}`)
      
      let lastError: any = null
      
      // å˜—è©¦ä¸åŒè¤‡é›œåº¦çš„æç¤º
      for (let i = 0; i < prompts.length; i++) {
        try {
          const prompt = prompts[i]
          logger.info(`ğŸ¯ Attempting analysis with prompt strategy ${i + 1}/${prompts.length}`)
          
          // ä½¿ç”¨çœŸæ­£çš„ Gemini 2.5 Flash å¤šæ¨¡æ…‹è¦–é »åˆ†æ
          const response = await this.callGeminiVideoAPI(gcsUri, prompt, videoId)

          logger.info(`âœ… Real video analysis completed`, {
            videoId,
            responseLength: response.length,
            preview: response.substring(0, 200),
            promptStrategy: i + 1
          })

          // è§£æ Gemini çš„å›æ‡‰
          return this.parseAnalysisResponse(response, videoId)
          
        } catch (error) {
          lastError = error
          logger.warn(`âš ï¸ Prompt strategy ${i + 1} failed, trying next...`, { error })
          
          // å¦‚æœæ˜¯æˆªæ–·éŒ¯èª¤ï¼Œç¹¼çºŒå˜—è©¦æ›´ç°¡å–®çš„æç¤º
          if (error instanceof Error && error.message.includes('truncat')) {
            continue
          }
          
          // å…¶ä»–éŒ¯èª¤ç›´æ¥æ‹‹å‡º
          throw error
        }
      }

      // æ‰€æœ‰ç­–ç•¥éƒ½å¤±æ•—
      logger.error('âŒ All prompt strategies failed', { gcsUri, videoId, lastError })
      throw new Error(`Real video analysis failed after all strategies: ${lastError}`)
      
    } catch (error) {
      logger.error('âŒ Gemini 2.5 Flash video analysis failed', { gcsUri, videoId, error })
      throw new Error(`Real video analysis failed: ${error}`)
    }
  }

  /**
   * ğŸ¯ æ ¸å¿ƒæ–¹æ³•ï¼šä½¿ç”¨ Gemini 2.5 Flash çœŸæ­£çš„è§†é¢‘åˆ†æåŠŸèƒ½
   */
  private async callGeminiVideoAPI(gcsUri: string, prompt: string, videoId: string): Promise<string> {
    const config = getVertexAIConfig()
    
    try {
      // è·å–è®¿é—®ä»¤ç‰Œ
      const authManager = getAuthManager()
      const accessToken = await authManager.getAccessToken()
      
      logger.info(`ğŸ”‘ Access token obtained for video analysis`)
      
      // æ„å»ºå¤šæ¨¡æ€è¯·æ±‚ä½“
      const requestBody = {
        contents: [{
          role: 'user',
          parts: [
            {
              text: prompt
            },
            {
              file_data: {
                mime_type: 'video/mp4',
                file_uri: gcsUri
              }
            }
          ]
        }],
        generationConfig: {
          temperature: 0.3,
          maxOutputTokens: 8192,  // ä¿æŒå……è¶³çš„è¼¸å‡ºç©ºé–“
          topP: 0.7,
          topK: 20
        },
        safetySettings: [
          {
            category: 'HARM_CATEGORY_HATE_SPEECH',
            threshold: 'BLOCK_MEDIUM_AND_ABOVE'
          },
          {
            category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
            threshold: 'BLOCK_MEDIUM_AND_ABOVE'
          },
          {
            category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
            threshold: 'BLOCK_MEDIUM_AND_ABOVE'
          },
          {
            category: 'HARM_CATEGORY_HARASSMENT',
            threshold: 'BLOCK_MEDIUM_AND_ABOVE'
          }
        ]
      }
      
      logger.info(`ğŸš€ Sending multimodal request to Gemini 2.5 Flash`, {
        videoId,
        gcsUri,
        promptLength: prompt.length
      })
      
      // è°ƒç”¨ Gemini 2.5 Flash API
      const response = await fetch(
        `https://${config.location}-aiplatform.googleapis.com/v1/projects/${config.projectId}/locations/${config.location}/publishers/google/models/gemini-2.5-flash:generateContent`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${accessToken}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(requestBody)
        }
      )
      
      if (!response.ok) {
        const errorText = await response.text()
        logger.error(`âŒ Gemini API request failed`, {
          status: response.status,
          statusText: response.statusText,
          error: errorText
        })
        throw new Error(`Gemini API error: ${response.status} ${response.statusText} - ${errorText}`)
      }
      
      const result = await response.json()
      
      logger.info(`âœ… Gemini 2.5 Flash response received`, {
        videoId,
        responseStructure: result.candidates ? 'Valid' : 'Invalid',
        candidatesCount: result.candidates?.length || 0
      })
      
      // æå–ç”Ÿæˆçš„æ–‡æœ¬
      if (result.candidates && result.candidates[0]?.content?.parts?.[0]?.text) {
        const generatedText = result.candidates[0].content.parts[0].text
        logger.info(`ğŸ“„ Generated analysis text length: ${generatedText.length}`)
        
        // é é˜²æ€§æª¢æŸ¥ï¼šå¦‚æœå›æ‡‰æ¥è¿‘æˆªæ–·é™åˆ¶ï¼Œç™¼å‡ºè­¦å‘Š
        if (generatedText.length > 9000) {
          logger.warn(`âš ï¸ Response approaching truncation limit`, {
            videoId,
            responseLength: generatedText.length,
            truncationRisk: 'HIGH'
          })
        }
        
        return generatedText
      } else {
        logger.error(`âŒ Unexpected response structure from Gemini`, {
          result: JSON.stringify(result, null, 2)
        })
        throw new Error('No valid content generated from Gemini video analysis')
      }
      
    } catch (error) {
      logger.error(`ğŸ’¥ Critical error in Gemini video API call`, {
        videoId,
        gcsUri,
        error: error instanceof Error ? error.message : String(error)
      })
      throw error
    }
  }

  private createAnalysisPrompt(): string {
    return `åˆ†æè¦–é »ï¼Œç”¨JSONå›ç­”ï¼ˆæ¥µç°¡ç‰ˆæœ¬ï¼‰ï¼š
{
  "generatedTranscript": "ä¸»è¦å°è©±/å‹•ä½œ50å­—å…§",
  "sceneBreakdown": [{"startTime":0,"endTime":30,"description":"å ´æ™¯","setting":"åœ°é»","actions":["å‹•ä½œ"],"visualDetails":"ç´°ç¯€"}],
  "characters": [{"name":"ä¸»è§’","description":"æè¿°10å­—","role":"è§’è‰²","appearances":[{"startTime":0,"endTime":30}],"characteristics":"ç‰¹å¾µ"}],
  "storyStructure": {"hook":"é–‹é ­5å­—","development":"ç™¼å±•5å­—","climax":"é«˜æ½®5å­—","resolution":"çµå°¾5å­—"},
  "audioAnalysis": {"hasDialogue":true,"backgroundMusic":"éŸ³æ¨‚","soundEffects":["éŸ³æ•ˆ"],"voiceCharacteristics":"è²éŸ³"},
  "mood": "æ°›åœ",
  "themes": ["ä¸»é¡Œ"],
  "cameraWork": "æ‹æ”",
  "contentSummary": "ç¸½çµ15å­—",
  "confidence": 0.9
}
è¦å‰‡ï¼šæœ€å¤š2å ´æ™¯2è§’è‰²ï¼Œæ¯å­—æ®µé™10å­—`
  }
  
  /**
   * è¶…ç´šç²¾ç°¡ç‰ˆæœ¬æç¤ºï¼ˆç•¶ç¬¬ä¸€å€‹ç‰ˆæœ¬ä»ç„¶å¤ªé•·æ™‚ä½¿ç”¨ï¼‰
   */
  private createMinimalAnalysisPrompt(): string {
    return `æ¥µç°¡JSONåˆ†æï¼š
{"generatedTranscript":"å…§å®¹20å­—","sceneBreakdown":[{"startTime":0,"endTime":30,"description":"å ´æ™¯"}],"characters":[],"storyStructure":{"hook":"é–‹","development":"å±•","climax":"è½‰","resolution":"åˆ"},"audioAnalysis":{"hasDialogue":true},"mood":"æ°›åœ","themes":["ä¸»é¡Œ"],"cameraWork":"æ‹æ”","contentSummary":"ç¸½çµ10å­—","confidence":0.8}`
  }

  private parseAnalysisResponse(responseText: string, videoId: string): VideoAnalysis {
    try {
      // æª¢æ¸¬å¯èƒ½çš„JSONæˆªæ–·
      const isTruncated = responseText.length > 9000 && !responseText.trim().endsWith('}')
      if (isTruncated) {
        logger.warn(`âš ï¸ JSON truncation detected, attempting recovery`, {
          videoId,
          responseLength: responseText.length,
          lastChars: responseText.slice(-100)
        })
      }
      
      // æ›´å¼·å¥çš„æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œç§»é™¤å¯èƒ½çš„ markdown æ ¼å¼å’Œä¸å®Œæ•´çš„JSON
      let cleanedResponse = responseText.trim()
      
      // ç§»é™¤ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
      if (cleanedResponse.startsWith('```json')) {
        cleanedResponse = cleanedResponse.replace(/```json\s*/g, '').replace(/\s*```$/g, '')
      } else if (cleanedResponse.startsWith('```')) {
        cleanedResponse = cleanedResponse.replace(/```\s*/g, '').replace(/\s*```$/g, '')
      }
      
      // æ‰¾åˆ°JSONé–‹å§‹å’ŒçµæŸä½ç½®
      const jsonStart = cleanedResponse.indexOf('{')
      let jsonEnd = cleanedResponse.lastIndexOf('}')
      
      if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
        cleanedResponse = cleanedResponse.substring(jsonStart, jsonEnd + 1)
      }
      
      // å¦‚æœæª¢æ¸¬åˆ°æˆªæ–·ï¼Œå˜—è©¦æ™ºèƒ½ä¿®å¾©
      if (isTruncated && !cleanedResponse.endsWith('}')) {
        cleanedResponse = this.repairTruncatedJson(cleanedResponse, videoId)
      }
      
      logger.info(`ğŸ§¹ Cleaned JSON for parsing`, {
        videoId,
        originalLength: responseText.length,
        cleanedLength: cleanedResponse.length,
        preview: cleanedResponse.substring(0, 200)
      })

      // è§£æ JSON
      const analysis = JSON.parse(cleanedResponse) as VideoAnalysis

      // é©—è­‰å¿…è¦æ¬„ä½
      if (!analysis.generatedTranscript) {
        throw new Error('Missing generated transcript')
      }

      // è¨­ç½®é è¨­å€¼
      analysis.confidence = analysis.confidence || 0.8
      analysis.sceneBreakdown = analysis.sceneBreakdown || []
      analysis.characters = analysis.characters || []
      analysis.dialogues = analysis.dialogues || []
      analysis.visualElements = analysis.visualElements || []
      analysis.keyMoments = analysis.keyMoments || []
      analysis.themes = analysis.themes || []
      analysis.cameraWork = analysis.cameraWork || 'æ¨™æº–æ‹æ”æ‰‹æ³•'
      analysis.contentSummary = analysis.contentSummary || 'å½±ç‰‡å…§å®¹åˆ†æ'
      
      // è¨­ç½®éŸ³é »åˆ†æé è¨­å€¼
      if (!analysis.audioAnalysis) {
        analysis.audioAnalysis = {
          hasDialogue: analysis.dialogues.length > 0,
          backgroundMusic: 'æœªæª¢æ¸¬åˆ°èƒŒæ™¯éŸ³æ¨‚',
          soundEffects: [],
          voiceCharacteristics: 'æœªåˆ†æèªéŸ³ç‰¹å¾µ'
        }
      }

      // å¦‚æœæ²’æœ‰æ•…äº‹çµæ§‹ï¼Œå‰µå»ºåŸºæœ¬çµæ§‹
      if (!analysis.storyStructure) {
        analysis.storyStructure = {
          hook: 'å½±ç‰‡é–‹é ­å¸å¼•è§€çœ¾æ³¨æ„',
          development: 'ä¸»è¦å…§å®¹å±•é–‹',
          climax: 'é—œéµæ™‚åˆ»æˆ–è½‰æŠ˜é»',
          resolution: 'çµå°¾ç¸½çµæˆ–è¡Œå‹•å‘¼ç±²'
        }
      }

      logger.info(`ğŸ“Š Analysis parsing successful`, {
        videoId,
        transcriptLength: analysis.generatedTranscript.length,
        scenesCount: analysis.sceneBreakdown.length,
        charactersCount: analysis.characters.length,
        dialoguesCount: analysis.dialogues.length
      })

      return analysis

    } catch (error) {
      logger.error('Failed to parse analysis response', {
        videoId,
        error,
        responseLength: responseText.length,
        responsePreview: responseText.substring(0, 500),
        responseEnd: responseText.slice(-200),
        errorPosition: error instanceof SyntaxError && error.message.includes('position') ? 
          error.message.match(/position (\d+)/)?.[1] : 'unknown'
      })

      // å˜—è©¦å¾éƒ¨åˆ†å…§å®¹ä¸­æå–æœ‰ç”¨ä¿¡æ¯
      const partialAnalysis = this.extractPartialAnalysis(responseText, videoId)
      if (partialAnalysis) {
        logger.info(`âœ… Recovered partial analysis for ${videoId}`)
        return partialAnalysis
      }

      // å‰µå»ºé™ç´šå›æ‡‰
      return this.createFallbackAnalysis(responseText, videoId)
    }
  }

  /**
   * æ™ºèƒ½ä¿®å¾©æˆªæ–·çš„JSON
   */
  private repairTruncatedJson(json: string, videoId: string): string {
    logger.info(`ğŸ”§ Attempting to repair truncated JSON for ${videoId}`)
    
    let repaired = json
    
    // è¨ˆç®—éœ€è¦çš„é–‰åˆæ‹¬è™Ÿ
    const openBraces = (json.match(/\{/g) || []).length
    const closeBraces = (json.match(/\}/g) || []).length
    const openBrackets = (json.match(/\[/g) || []).length
    const closeBrackets = (json.match(/\]/g) || []).length
    
    // å¦‚æœJSONåœ¨å­—ç¬¦ä¸²ä¸­é–“æˆªæ–·ï¼Œå˜—è©¦é–‰åˆç•¶å‰å­—ç¬¦ä¸²
    if (json.includes('"') && !json.endsWith('"') && !json.endsWith('}')) {
      const lastQuote = json.lastIndexOf('"')
      const afterLastQuote = json.substring(lastQuote + 1)
      // å¦‚æœæœ€å¾Œä¸€å€‹å¼•è™Ÿå¾Œæœ‰å…§å®¹ä½†æ²’æœ‰é–‰åˆï¼Œæ·»åŠ å¼•è™Ÿ
      if (afterLastQuote.length > 0 && !afterLastQuote.includes('"')) {
        repaired += '"'
      }
    }
    
    // é–‰åˆæ•¸çµ„
    for (let i = 0; i < openBrackets - closeBrackets; i++) {
      repaired += ']'
    }
    
    // é–‰åˆå°è±¡
    for (let i = 0; i < openBraces - closeBraces; i++) {
      repaired += '}'
    }
    
    logger.info(`ğŸ”§ JSON repair completed`, {
      videoId,
      originalLength: json.length,
      repairedLength: repaired.length,
      addedChars: repaired.length - json.length
    })
    
    return repaired
  }
  
  /**
   * å¾éƒ¨åˆ†éŸ¿æ‡‰ä¸­æå–å¯ç”¨çš„åˆ†ææ•¸æ“š
   */
  private extractPartialAnalysis(responseText: string, videoId: string): VideoAnalysis | null {
    try {
      logger.info(`ğŸ” Attempting to extract partial analysis for ${videoId}`)
      
      // æå–ç”Ÿæˆçš„è½‰éŒ„æ–‡æœ¬
      const transcriptMatch = responseText.match(/"generatedTranscript"\s*:\s*"([\s\S]*?)"/)
      const transcript = transcriptMatch ? transcriptMatch[1].replace(/\\n/g, '\n').replace(/\\"/g, '"') : ''
      
      // æå–å ´æ™¯ä¿¡æ¯
      const scenesMatch = responseText.match(/"sceneBreakdown"\s*:\s*\[([\s\S]*?)\]/)
      let scenes: any[] = []
      if (scenesMatch) {
        try {
          scenes = JSON.parse(`[${scenesMatch[1]}]`)
        } catch {
          // å¿½ç•¥å ´æ™¯è§£æéŒ¯èª¤
        }
      }
      
      // æå–è§’è‰²ä¿¡æ¯
      const charactersMatch = responseText.match(/"characters"\s*:\s*\[([\s\S]*?)\]/)
      let characters: any[] = []
      if (charactersMatch) {
        try {
          characters = JSON.parse(`[${charactersMatch[1]}]`)
        } catch {
          // å¿½ç•¥è§’è‰²è§£æéŒ¯èª¤
        }
      }
      
      if (transcript && transcript.length > 50) {
        logger.info(`âœ… Successfully extracted partial analysis`, {
          videoId,
          transcriptLength: transcript.length,
          scenesCount: scenes.length,
          charactersCount: characters.length
        })
        
        return {
          generatedTranscript: transcript,
          sceneBreakdown: scenes.length > 0 ? scenes : this.createDefaultScenes(),
          characters: characters.length > 0 ? characters : [],
          dialogues: [],
          visualElements: [],
          storyStructure: {
            hook: 'å½±ç‰‡é–‹é ­éƒ¨åˆ†',
            development: 'ä¸»è¦å…§å®¹å±•é–‹',
            climax: 'é—œéµæ™‚åˆ»',
            resolution: 'çµå°¾è™•ç†'
          },
          audioAnalysis: {
            hasDialogue: transcript.includes('å°è©±') || transcript.includes('èªª'),
            backgroundMusic: 'èƒŒæ™¯éŸ³æ¨‚åˆ†æ',
            soundEffects: [],
            voiceCharacteristics: 'èªéŸ³ç‰¹å¾µåˆ†æ'
          },
          mood: 'å¾éƒ¨åˆ†å…§å®¹æ¨æ–·çš„æ°›åœ',
          themes: ['éƒ¨åˆ†åˆ†æä¸»é¡Œ'],
          cameraWork: 'æ”å½±æ‰‹æ³•åˆ†æ',
          keyMoments: [],
          contentSummary: transcript.length > 100 ? transcript.substring(0, 100) + '...' : transcript,
          confidence: 0.6 // ä¸­ç­‰ä¿¡å¿ƒåº¦ï¼Œå› ç‚ºæ˜¯éƒ¨åˆ†åˆ†æ
        }
      }
      
      return null
      
    } catch (error) {
      logger.warn(`Failed to extract partial analysis for ${videoId}`, { error })
      return null
    }
  }
  
  /**
   * å‰µå»ºé»˜èªå ´æ™¯çµæ§‹
   */
  private createDefaultScenes(): any[] {
    return [
      {
        startTime: 0,
        endTime: 20,
        description: 'å½±ç‰‡é–‹å§‹å ´æ™¯',
        setting: 'åˆå§‹ç’°å¢ƒ',
        actions: ['é–‹å ´å‹•ä½œ'],
        visualDetails: 'è¦–è¦ºç´°ç¯€'
      }
    ]
  }

  private createFallbackAnalysis(rawResponse: string, videoId: string): VideoAnalysis {
    logger.warn(`Creating fallback analysis for ${videoId}`)
    
    return {
      generatedTranscript: rawResponse.length > 1000 ? rawResponse.substring(0, 1000) + '...' : rawResponse,
      sceneBreakdown: [{
        startTime: 0,
        endTime: 30,
        description: 'å½±ç‰‡å ´æ™¯åˆ†æå¤±æ•—ï¼Œä½¿ç”¨åŸå§‹å›æ‡‰',
        setting: 'æœªçŸ¥ç’°å¢ƒ',
        actions: ['åˆ†æä¸­ç™¼ç”ŸéŒ¯èª¤'],
        visualDetails: 'åˆ†æå¤±æ•—'
      }],
      characters: [],
      dialogues: [],
      visualElements: [],
      storyStructure: {
        hook: 'é–‹é ­å…§å®¹',
        development: 'ä¸»è¦å…§å®¹',
        climax: 'é‡é»æ™‚åˆ»',
        resolution: 'çµå°¾éƒ¨åˆ†'
      },
      audioAnalysis: {
        hasDialogue: false,
        backgroundMusic: 'æœªåˆ†æ',
        soundEffects: [],
        voiceCharacteristics: 'æœªåˆ†æ'
      },
      mood: 'æœªçŸ¥',
      themes: [],
      cameraWork: 'æœªåˆ†æ',
      keyMoments: [],
      contentSummary: 'åˆ†æå¤±æ•—ï¼Œä½¿ç”¨é™ç´šæ¨¡å¼',
      confidence: 0.3 // ä½ä¿¡å¿ƒåº¦è¡¨ç¤ºé€™æ˜¯é™ç´šå›æ‡‰
    }
  }

  private async cleanupTempStorage(gcsUri: string): Promise<void> {
    try {
      const uriParts = gcsUri.replace('gs://', '').split('/')
      const bucketName = uriParts[0]
      const fileName = uriParts.slice(1).join('/')

      await this.storage.bucket(bucketName).file(fileName).delete()
      logger.info(`ğŸ§¹ Cleaned up GCS temp file: ${gcsUri}`)

    } catch (error) {
      logger.warn(`âš ï¸ Failed to cleanup GCS file: ${gcsUri}`, { error })
    }
  }

  // æª¢æŸ¥æœå‹™å¯ç”¨æ€§
  async checkAvailability(): Promise<boolean> {
    try {
      // ä½¿ç”¨ GeminiDirectService é€²è¡Œæ¸¬è©¦
      const testResponse = await this.geminiService.generateText(
        'Hello, are you available for video analysis?', 
        {
          temperature: 0.1,
          maxOutputTokens: 50
        }
      )

      const hasResponse = testResponse.length > 0
      logger.info(`âœ… Gemini video analysis service available: ${hasResponse}`)
      return hasResponse

    } catch (error) {
      logger.error('âŒ Gemini video analysis service unavailable', { error })
      return false
    }
  }
}

// å–®ä¾‹å¯¦ä¾‹
export const geminiVideoAnalyzer = new GeminiVideoAnalyzer()